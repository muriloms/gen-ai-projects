{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0bd547-daf6-473f-88da-f7c55e475bca",
   "metadata": {},
   "source": [
    "### Criando um NLP Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53dc52-27be-42af-987f-af36502d4008",
   "metadata": {},
   "source": [
    "Traduzir idiomas não é uma tarefa fácil, especialmente dadas as complexidades, nuances e contextos culturais embutidos neles. Central para o sucesso desse esforço são os dados - grandes corpora de frases bilíngues que servem como base para seus modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdd7c5-5ff7-472d-ade5-40e2234b096e",
   "metadata": {},
   "source": [
    "No PyTorch, o data loader desempenha um papel indispensável na gestão de grandes volumes de dados. Para tarefas de processamento de linguagem natural (NLP), os dados geralmente possuem comprimentos variáveis devido às diferentes estruturas e tamanhos das frases entre línguas. O data loader organiza de forma eficiente esses dados em batches de sequências de comprimento variável, garantindo que seus modelos sejam treinados em exemplos diversificados a cada iteração. Esse agrupamento é crucial para aproveitar o poder da computação paralela em GPUs, acelerando o processo de treinamento.\n",
    "\n",
    "Além disso, o data loader ajuda a embaralhar o conjunto de dados, o que é essencial para evitar que os modelos memorizem a sequência dos dados de treinamento, promovendo uma melhor generalização. Isso é especialmente importante em tarefas de NLP, onde os dados podem estar ordenados ou agrupados por tópicos. O embaralhamento garante que o modelo permaneça robusto e não desenvolva vieses com base na ordem dos dados de entrada.\n",
    "\n",
    "Por fim, no contexto de NLP, etapas de pré-processamento como tokenização, preenchimento (padding) e conversão para valores numéricos são fundamentais. O data loader no PyTorch fornece ganchos que permitem integrar essas etapas de pré-processamento de maneira fluida, assegurando que os dados textuais brutos sejam transformados em um formato adequado para modelos de aprendizado profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07921905-6f23-4f9c-8c4f-82814f88810c",
   "metadata": {},
   "source": [
    "#### 1. Instalar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a568acb7-71b2-4897-9620-638d8556d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_and_install(package, pip_name=None):\n",
    "    if pip_name is None:\n",
    "        pip_name = package\n",
    "    spec = importlib.util.find_spec(package)\n",
    "    if spec is None:\n",
    "        print(f\"{package} não está instalado. Instalando...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name])\n",
    "    else:\n",
    "        print(f\"{package} já está instalado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f04dc4-5f72-4c1e-b5b2-0464c98be6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq torchtext #0.14.1\n",
    "#!pip install -Uqq torch #1.13.1\n",
    "#!pip install -Uqq spacy\n",
    "#!pip install -Uqq torchdata #0.5.1\n",
    "#!pip install -Uqq portalocker>=2.0.0\n",
    "#!python -m spacy download en_core_web_sm -qq\n",
    "#!python -m spacy download de_core_news_sm -qq\n",
    "#!python -m spacy download fr_core_news_sm -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5382f1e6-90e4-4e9c-a925-016e63108ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchtext já está instalado.\n",
      "torch já está instalado.\n",
      "spacy já está instalado.\n",
      "torchdata já está instalado.\n",
      "portalocker não está instalado. Instalando...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando e instalando pacotes\n",
    "check_and_install('torchtext', 'torchtext==0.15.2')\n",
    "check_and_install('torch', 'torch==2.0.3')\n",
    "check_and_install('spacy')\n",
    "check_and_install('torchdata', 'torchdata==0.5.1')\n",
    "check_and_install('portalocker')\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"de_core_news_sm\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e0a57-cfd0-4b9a-b5ba-1a3e5e00f175",
   "metadata": {},
   "source": [
    "#### 2. Carregar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4c43fc-ef52-459c-bd82-d25f38a5314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15.2\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e394d36-f960-4f39-8026-7906c275f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
    "import torchtext\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435054-e403-451b-a625-146babb15cba",
   "metadata": {},
   "source": [
    "#### Conjunto de Dados\n",
    "No PyTorch, um data set é um objeto que representa uma coleção de amostras de dados. Cada amostra de dados normalmente consiste em uma ou mais características de entrada e seus respectivos rótulos de destino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52308d-2724-4564-b1d6-bb28dd751dbc",
   "metadata": {},
   "source": [
    "#### Data Loader\n",
    "Um data loader no PyTorch é responsável por carregar e organizar os dados de um data set de forma eficiente. Ele simplifica o processo de iteração sobre um data set, embaralhamento e divisão em batches para o treinamento. Em aplicações de NLP, o data loader é utilizado para processar e transformar os dados textuais, e não apenas para carregar o conjunto de dados.\n",
    "\n",
    "Os data loaders possuem vários parâmetros importantes, incluindo o data set a ser carregado, o tamanho do batch (determinando quantas amostras por batch), shuffle (para definir se os dados serão embaralhados a cada época) e outros. Eles também fornecem uma interface de iterador, facilitando a iteração sobre batches de dados durante o treinamento.\n",
    "\n",
    "Agora, você pode se perguntar: \"O que é um iterador?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac718fd-149b-430c-a041-ff38a811628c",
   "metadata": {},
   "source": [
    "Um iterador é um objeto que pode ser percorrido em um loop. Ele contém elementos que podem ser iterados e geralmente inclui dois métodos, `__iter__()` e `__next__()`. Quando não há mais elementos para iterar, ele gera uma exceção StopIteration.\n",
    "\n",
    "Iteradores são comumente usados para percorrer grandes conjuntos de dados sem carregar todos os elementos na memória ao mesmo tempo, tornando o processo mais eficiente em termos de memória. No PyTorch, nem todos os data sets são iteradores, mas todos os data loaders são.\n",
    "\n",
    "No PyTorch, o data loader processa dados em batches, carregando e processando um lote de cada vez na memória de forma eficiente. O tamanho do batch, que você especifica ao criar o data loader, determina quantas amostras são processadas juntas em cada lote. O propósito do data loader é converter os dados de entrada e os rótulos em batches de tensores com a mesma forma, para que possam ser interpretados por modelos de aprendizado profundo.\n",
    "\n",
    "Por fim, um data loader pode ser usado para tarefas como tokenização, sequenciamento, padronização do tamanho das amostras e transformação dos dados em tensores que seu modelo possa entender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cc600-9981-4d74-b700-c4be9c40385c",
   "metadata": {},
   "source": [
    "#### Conjunto de Dados Personalizado e Data Loader no PyTorch\n",
    "O conjunto de dados abaixo consiste em uma lista de frases aleatórias, e o objetivo é criar batches de frases para processamento posterior, como o treinamento de um modelo de rede neural.\n",
    "\n",
    "Primeiro definimos um conjunto de dados personalizado chamado CustomDataset. Esse conjunto de dados herda da classe torch.utils.data.Dataset e é inicializado com uma lista de frases. O conjunto de dados inclui dois métodos essenciais:\n",
    "\n",
    "- `__init__(self, sentences)`: Inicializa o conjunto de dados com uma lista de frases.\n",
    "- `__getitem__(self, idx)`: Recupera um item (neste caso, uma frase) em um índice específico, idx.\n",
    "\n",
    "Em seguida, é criado uma instância do conjunto de dados personalizado (custom_dataset) passando a lista de frases. Além disso, podemos especificar um tamanho de batch (batch_size), que determina quantas frases serão agrupadas em cada batch durante o carregamento de dados.\n",
    "\n",
    "É criado um DataLoader (dataloader) fornecendo o conjunto de dados personalizado e o tamanho de batch para a classe torch.utils.data.DataLoader. Além disso, é definido o shuffle=True, indicando que as frases serão embaralhadas aleatoriamente antes de serem divididas em batches. Esse embaralhamento é especialmente útil para o treinamento de modelos de aprendizado profundo, pois impede que o modelo aprenda padrões com base na ordem dos dados.\n",
    "\n",
    "Por fim, itera pelo DataLoader para demonstrar como os dados são carregados em batches. Neste código, o tamanho do batch é definido como 2, o que significa que cada batch conterá duas frases. O DataLoader gerencia eficientemente o carregamento de dados em batches, tornando-o adequado para o treinamento de modelos de aprendizado profundo.\n",
    "\n",
    "Durante a iteração, as frases em cada batch são impressas para ilustrar como o DataLoader agrupa e apresenta os dados. Esse trecho de código fornece um exemplo fundamental de como configurar um conjunto de dados personalizado e um data loader no PyTorch, uma prática comum em fluxos de trabalho de aprendizado profundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5468ffbf-ff06-4abd-9d4e-a7e75de0624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
    "    \"Fame's a fickle friend, Harry.\",\n",
    "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
    "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
    "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
    "    \"You are awesome!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fed29b72-80cc-4056-b2ad-075072079cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "309f5d60-28ed-4b1f-926a-c2fd69f923a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your custom dataset\n",
    "custom_dataset = CustomDataset(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e47862c0-e579-4ea7-9cf7-365f10f7acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "087d4045-4717-4c6f-8377-a0948a24ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataloader = DataLoader(custom_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2585360f-df2f-4270-bf61-5893150840a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.', 'Soon we must all face the choice between what is right and what is easy.']\n",
      "[\"Fame's a fickle friend, Harry.\", 'It is our choices, Harry, that show what we truly are, far more than our abilities.']\n",
      "['You are awesome!', \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\"]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852e55b-f92e-4e02-a240-c8f9d09bd013",
   "metadata": {},
   "source": [
    "Conforme mostrado acima, os dados são organizados em lotes de 2 frases cada. É importante notar que os modelos de aprendizado profundo só podem compreender dados numéricos, e as palavras não têm sentido para eles. Portanto, o próximo passo é converter essas frases em tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e05b78-8119-4d84-ad06-5c55fea8a1b4",
   "metadata": {},
   "source": [
    "#### Criação de Tensores para Conjunto de Dados Personalizado\n",
    "Neste exemplo de código, é construído de um conjunto de dados personalizado para tarefas de processamento de linguagem natural (NLP) usando PyTorch. O conjunto de dados consiste em uma lista de frases, e o objetivo é pré-processar essas frases, tokenizá-las e convertê-las em tensores de índices de tokens para uso em modelos de NLP. \n",
    "\n",
    "As frases e a classe CustomDataset são utilizadas da mesma forma que no trecho de código anterior. As mudanças feitas na classe CustomDataset são as seguintes:\n",
    "\n",
    "- `__init__`: O construtor recebe uma lista de frases, uma função de tokenização e um vocabulário (vocab) como entrada.\n",
    "- `__len__`: Este método retorna o número total de amostras no conjunto de dados.\n",
    "- `__getitem__`: Este método é responsável por processar uma única amostra. Ele tokeniza a frase usando o tokenizador fornecido e, em seguida, converte os tokens em índices de tensor usando o vocabulário.\n",
    "\n",
    "Podemos definir um tokenizador usando a função get_tokenizer com a opção basic_english. A tokenização é o processo de dividir um texto em tokens ou palavras individuais. Em seguida, é construído um vocabulário a partir das frases.A função build_vocab_from_iterator é utilizada para construir o vocabulário a partir das frases tokenizadas.\n",
    "\n",
    "É possível criar uma instância do seu conjunto de dados personalizado, passando as frases, o tokenizador e o vocabulário. Finalmente, imprime o comprimento do conjunto de dados personalizado e amostras dele para ilustração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d07b59a-496f-4f02-9ac1-676255e303de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
    "    \"Fame's a fickle friend, Harry.\",\n",
    "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
    "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
    "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
    "    \"You are awesome!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8814fad1-e31a-40bb-8105-2597f7247e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data set\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, vocab):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.sentences[idx])\n",
    "        # Convert tokens to tensor indices using vocab\n",
    "        tensor_indices = [self.vocab[token] for token in tokens]\n",
    "        return torch.tensor(tensor_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f710587c-e584-4073-bdab-e99a012ca440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b38cb249-2dbf-4488-9802-0f8fd4e1aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff510e5c-7515-45ce-9380-3921e3b64c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your custom data set\n",
    "custom_dataset = CustomDataset(sentences, tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "736be890-10d6-4ab9-9f30-1d9cbf13db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset Length: 6\n",
      "Sample Items:\n",
      "Item 1: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
      "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
      "\n",
      "\n",
      "Item 2: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1])\n",
      "\n",
      "\n",
      "Item 3: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
      "        21,  1])\n",
      "\n",
      "\n",
      "Item 4: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n",
      "\n",
      "\n",
      "Item 5: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
      "         2, 12, 64, 17, 26, 65,  1])\n",
      "\n",
      "\n",
      "Item 6: tensor([19,  4, 25, 20])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom Dataset Length:\", len(custom_dataset))\n",
    "print(\"Sample Items:\")\n",
    "for i in range(6):\n",
    "    sample_item = custom_dataset[i]\n",
    "    print(f\"Item {i + 1}: {sample_item}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa01fd-273e-4a18-a0b2-ad6fd9139335",
   "metadata": {},
   "source": [
    "#### Função de Colagem Personalizada (collate function)\n",
    "Uma função de colagem (collate function) é utilizada no contexto de carregamento e agrupamento de dados em aprendizado de máquina, especialmente quando se lida com dados de comprimento variável, como sequências (e.g., texto, séries temporais, sequências de eventos). Seu principal objetivo é preparar e formatar amostras individuais de dados (exemplos) em batches que possam ser processados de forma eficiente por modelos de aprendizado de máquina.\n",
    "\n",
    "É definida uma função de colagem personalizada chamada collate_fn. Essa função desempenha um papel crucial ao lidar com sequências de comprimentos variados, como frases em NLP. Seu propósito é preencher (pad) as sequências dentro de um batch para que tenham comprimentos iguais, o que é uma etapa comum de pré-processamento em tarefas de NLP.\n",
    "\n",
    "- `pad_sequence`: Esta função faz parte do PyTorch e é usada para preencher as sequências em um batch, garantindo um comprimento uniforme. Ela recebe um batch de sequências como entrada e as preenche para igualar o comprimento da sequência mais longa. O argumento `padding_value=0` especifica o valor a ser utilizado para o preenchimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce58fefd-f78e-47ef-8645-0c23654be185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom collate function\n",
    "def collate_fn(batch):\n",
    "    # Pad sequences within the batch to have equal lengths\n",
    "    padded_batch = pad_sequence(batch,\n",
    "                                batch_first=True,\n",
    "                                padding_value=0)\n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28db6e-6eaa-4815-a315-6a61d2b11574",
   "metadata": {},
   "source": [
    "Na célula acima, ao preencher as sequências, você define batch_first=True. Quando batch_first=True, a saída estará no formato `[batch_size x seq_len]`; caso contrário, estará no formato `[seq_len x batch_size]`. Alguns modelos aceitam a entrada no formato `[batch_size x seq_len]`, enquanto outros precisam que a entrada esteja no formato `[seq_len x batch_size]`. Esse parâmetro cuida de organizar a entrada na forma desejada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a4315a-4636-482f-9d78-fe7b0e655147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader with the custom collate function with batch_first=True,\n",
    "dataloader = DataLoader(custom_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "745ead64-4bb0-47b6-ae30-2bdda0c94aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n",
      "['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
      "['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.']\n",
      "['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', ',', ',', ',', ',']\n",
      "['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n",
      "['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data loader\n",
    "for batch in dataloader:\n",
    "    for row in batch:\n",
    "        for idx in row:\n",
    "            words = [vocab.get_itos()[idx] for idx in row]\n",
    "        print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7176b7-04e9-40c5-92fd-b556f6de93be",
   "metadata": {},
   "source": [
    "Agora, você pode tentar `batch_first=False`, que é o valor PADRÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "437759b4-3d56-4da7-ba0c-3ddc8079e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom collate function\n",
    "def collate_fn_bfFALSE(batch):\n",
    "    # Pad sequences within the batch to have equal lengths\n",
    "    padded_batch = pad_sequence(batch, padding_value=0)\n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96fb2ac8-d717-4b39-939d-3e027d791ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader with the custom collate function with batch_first=True,\n",
    "dataloader_bfFALSE = DataLoader(custom_dataset, \n",
    "                                batch_size=batch_size, \n",
    "                                collate_fn=collate_fn_bfFALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9aa5d545-b8df-46af-805b-0b01896f7f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', 'fame']\n",
      "['you', \"'\"]\n",
      "['want', 's']\n",
      "['to', 'a']\n",
      "['know', 'fickle']\n",
      "['what', 'friend']\n",
      "['a', ',']\n",
      "['man', 'harry']\n",
      "[\"'\", '.']\n",
      "['s', ',']\n",
      "['like', ',']\n",
      "[',', ',']\n",
      "['take', ',']\n",
      "['a', ',']\n",
      "['good', ',']\n",
      "['look', ',']\n",
      "['at', ',']\n",
      "['how', ',']\n",
      "['he', ',']\n",
      "['treats', ',']\n",
      "['his', ',']\n",
      "['inferiors', ',']\n",
      "[',', ',']\n",
      "['not', ',']\n",
      "['his', ',']\n",
      "['equals', ',']\n",
      "['.', ',']\n",
      "['it', 'soon']\n",
      "['is', 'we']\n",
      "['our', 'must']\n",
      "['choices', 'all']\n",
      "[',', 'face']\n",
      "['harry', 'the']\n",
      "[',', 'choice']\n",
      "['that', 'between']\n",
      "['show', 'what']\n",
      "['what', 'is']\n",
      "['we', 'right']\n",
      "['truly', 'and']\n",
      "['are', 'what']\n",
      "[',', 'is']\n",
      "['far', 'easy']\n",
      "['more', '.']\n",
      "['than', ',']\n",
      "['our', ',']\n",
      "['abilities', ',']\n",
      "['.', ',']\n",
      "['youth', 'you']\n",
      "['can', 'are']\n",
      "['not', 'awesome']\n",
      "['know', '!']\n",
      "['how', ',']\n",
      "['age', ',']\n",
      "['thinks', ',']\n",
      "['and', ',']\n",
      "['feels', ',']\n",
      "['.', ',']\n",
      "['but', ',']\n",
      "['old', ',']\n",
      "['men', ',']\n",
      "['are', ',']\n",
      "['guilty', ',']\n",
      "['if', ',']\n",
      "['they', ',']\n",
      "['forget', ',']\n",
      "['what', ',']\n",
      "['it', ',']\n",
      "['was', ',']\n",
      "['to', ',']\n",
      "['be', ',']\n",
      "['young', ',']\n",
      "['.', ',']\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data loader\n",
    "for seq in dataloader_bfFALSE:\n",
    "    for row in seq:\n",
    "        #print(row)\n",
    "        words = [vocab.get_itos()[idx] for idx in row]\n",
    "        print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11999fe4-d878-4ebb-8ebc-409735e3daf2",
   "metadata": {},
   "source": [
    "Pode ser visto que a primeira dimensão agora é a sequência em vez do lote, o que significa que as sentenças serão quebradas para que cada linha inclua um token de cada sequência. Por exemplo, a primeira linha, (['if', 'fame']), inclui os primeiros tokens de todas as sequências naquele lote. Precisamos estar ciente desse padrão para evitar qualquer confusão ao trabalhar com redes neurais recorrentes (RNNs) e transformadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cc273cd-f562-4102-b3e0-053b858a19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
      "         43, 61,  9, 44,  0, 14,  9, 33,  1],\n",
      "        [35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "Length of sequences in the batch: 27 \n",
      "---\n",
      "tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
      "         21,  1],\n",
      "        [54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
      "          0,  0]])\n",
      "Length of sequences in the batch: 20 \n",
      "---\n",
      "tensor([[66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
      "          2, 12, 64, 17, 26, 65,  1],\n",
      "        [19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "Length of sequences in the batch: 25 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data loader with batch_first = TRUE\n",
    "for batch in dataloader:    \n",
    "    print(batch)\n",
    "    print(\"Length of sequences in the batch:\",batch.shape[1], \"\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae8ca7-fe1f-41bf-a2a8-0bac0b00a7ca",
   "metadata": {},
   "source": [
    "Também temos a opção de utilizar a função collate para tarefas como tokenização, conversão de índices tokenizados e transformação do resultado em um tensor. É importante observar que o conjunto de dados original permanece intocado por essas transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b6115c1-d24d-447f-84ae-882cebd25057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data set\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eec08a9-b4ae-42ef-aba4-deca60664b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset=CustomDataset(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7901b3b3-6fac-49f0-aac5-556d398c582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3150d153-bd81-4348-951e-99588fd5f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Tokenize each sample in the batch using the specified tokenizer\n",
    "    tensor_batch = []\n",
    "    for sample in batch:\n",
    "        tokens = tokenizer(sample)\n",
    "        # Convert tokens to vocabulary indices and create a tensor for each sample\n",
    "        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
    "\n",
    "    # Pad sequences within the batch to have equal lengths using pad_sequence\n",
    "    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)\n",
    "    padded_batch = pad_sequence(tensor_batch, batch_first=True)\n",
    "    \n",
    "    # Return the padded batch\n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bef468d-b94f-465c-b1d8-52f168a31fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader for the custom dataset\n",
    "dataloader = DataLoader(\n",
    "    dataset=custom_dataset,   # Custom PyTorch Dataset containing your data\n",
    "    batch_size=batch_size,     # Number of samples in each mini-batch\n",
    "    shuffle=True,              # Shuffle the data at the beginning of each epoch\n",
    "    collate_fn=collate_fn      # Custom collate function for processing batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2607737a-1ecc-481c-ad97-c56fd33c989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
      "          2, 12, 64, 17, 26, 65,  1]])\n",
      "shape of sample 2 \n",
      "---\n",
      "tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
      "         21,  1,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
      "         43, 61,  9, 44,  0, 14,  9, 33,  1]])\n",
      "shape of sample 2 \n",
      "---\n",
      "tensor([[35,  6, 16,  3, 38, 40,  0,  8,  1],\n",
      "        [19,  4, 25, 20,  0,  0,  0,  0,  0]])\n",
      "shape of sample 2 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    print(\"shape of sample\",len(batch), \"\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef350b-a006-4029-96d9-f4d11c31a6d0",
   "metadata": {},
   "source": [
    "____\n",
    "Esse material tem como referência o curso [Generative AI and LLMs: Architecture and Data Preparation](https://www.coursera.org/learn/generative-ai-llm-architecture-data-preparation?specialization=generative-ai-engineering-with-llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be370c8-c18b-40b6-9927-4124e031b1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
